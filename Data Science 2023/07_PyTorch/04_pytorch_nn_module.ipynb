{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "2fGV-aAltJcL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "sfRjLJNRtaSg",
        "outputId": "e52a5d33-9e3f-4de0-9e6c-f9afb3cfa0a6"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f86d0615-d06f-4883-bbc3-d78107e7b7a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f86d0615-d06f-4883-bbc3-d78107e7b7a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f86d0615-d06f-4883-bbc3-d78107e7b7a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f86d0615-d06f-4883-bbc3-d78107e7b7a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f793da5-32da-4c2d-8eae-ab210c4d91ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f793da5-32da-4c2d-8eae-ab210c4d91ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f793da5-32da-4c2d-8eae-ab210c4d91ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['id', 'Unnamed: 32'], inplace= True)"
      ],
      "metadata": {
        "id": "OIK_WacYte3E"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdeXxTcEtk96",
        "outputId": "9417ce0f-4128-4eb7-af43-2ead4a98c290"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
      ],
      "metadata": {
        "id": "czTGUN60tn1h"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "j2JmUakKt0uw"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d69Sf11PuSnA",
        "outputId": "d96f6f9f-0efa-48fe-a02b-a0d1c76cf111"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.25566705, -0.55684049,  1.18084608, ...,  0.7734216 ,\n",
              "        -0.03098482,  0.02636565],\n",
              "       [-1.24880238, -0.08696776, -1.24141136, ..., -1.06827112,\n",
              "         0.44155951, -0.21007074],\n",
              "       [-0.65961457, -0.18564103, -0.58971943, ...,  0.57941562,\n",
              "         2.89034054,  2.96939039],\n",
              "       ...,\n",
              "       [ 0.02000149,  0.03754851,  0.22082241, ...,  0.51727308,\n",
              "        -0.80708411,  1.27678091],\n",
              "       [ 0.11548474,  0.89271687,  0.06360173, ...,  0.295985  ,\n",
              "        -0.68347153, -0.8305179 ],\n",
              "       [-0.18219833, -1.20526485, -0.20155542, ...,  0.18837231,\n",
              "         0.09888663, -0.60677609]])"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "wHDoVtwwvYSY"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lRC7tFyuWXK",
        "outputId": "f546c71d-4c59-4371-852b-9e886a5d88f1"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "y_train_tensor = torch.from_numpy(y_train)\n",
        "y_test_tensor = torch.from_numpy(y_test)"
      ],
      "metadata": {
        "id": "CO4Tu4WiuXJD"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tensor.shape)\n",
        "print(y_train_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8s9FoxSut0z",
        "outputId": "90329e54-9f12-4eed-81f3-83fe98eeafea"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([455, 30])\n",
            "torch.Size([455])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class mysimplenn(nn.Module):\n",
        "  def __init__(self, num_feature):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(num_feature, 8),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(8, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, feature):\n",
        "    out = self.network(feature)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "4k4kENynuzHj"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "epochs = 250\n",
        "loss_function = nn.BCELoss()"
      ],
      "metadata": {
        "id": "utkQCtP_wkXC"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = mysimplenn(X_train_tensor.shape[1])\n",
        "# optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "# define loop\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "  # forward pass\n",
        "  y_pred = model(X_train_tensor)\n",
        "  # calculate loss\n",
        "  loss = loss_function(y_pred, y_train_tensor.view(-1,1).float())\n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "  # parameters update\n",
        "  optimizer.step()\n",
        "\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYwcrYsjwo_y",
        "outputId": "485e5617-5a1b-4535-d62b-35102dc190bd"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.6380380988121033\n",
            "Epoch: 2, Loss: 0.5966582894325256\n",
            "Epoch: 3, Loss: 0.5565816164016724\n",
            "Epoch: 4, Loss: 0.5170019865036011\n",
            "Epoch: 5, Loss: 0.47800490260124207\n",
            "Epoch: 6, Loss: 0.4401032626628876\n",
            "Epoch: 7, Loss: 0.4041580259799957\n",
            "Epoch: 8, Loss: 0.3704407513141632\n",
            "Epoch: 9, Loss: 0.3392222225666046\n",
            "Epoch: 10, Loss: 0.31056106090545654\n",
            "Epoch: 11, Loss: 0.2845749258995056\n",
            "Epoch: 12, Loss: 0.2611085772514343\n",
            "Epoch: 13, Loss: 0.2399936318397522\n",
            "Epoch: 14, Loss: 0.2211429327726364\n",
            "Epoch: 15, Loss: 0.20440508425235748\n",
            "Epoch: 16, Loss: 0.1895008534193039\n",
            "Epoch: 17, Loss: 0.17619162797927856\n",
            "Epoch: 18, Loss: 0.16428299248218536\n",
            "Epoch: 19, Loss: 0.1536107063293457\n",
            "Epoch: 20, Loss: 0.14406253397464752\n",
            "Epoch: 21, Loss: 0.13542479276657104\n",
            "Epoch: 22, Loss: 0.1277277022600174\n",
            "Epoch: 23, Loss: 0.12085023522377014\n",
            "Epoch: 24, Loss: 0.1146627739071846\n",
            "Epoch: 25, Loss: 0.10899467766284943\n",
            "Epoch: 26, Loss: 0.1038212701678276\n",
            "Epoch: 27, Loss: 0.09909684956073761\n",
            "Epoch: 28, Loss: 0.09482759237289429\n",
            "Epoch: 29, Loss: 0.09098473936319351\n",
            "Epoch: 30, Loss: 0.08752351999282837\n",
            "Epoch: 31, Loss: 0.08441103994846344\n",
            "Epoch: 32, Loss: 0.08165212720632553\n",
            "Epoch: 33, Loss: 0.07919881492853165\n",
            "Epoch: 34, Loss: 0.07701312750577927\n",
            "Epoch: 35, Loss: 0.07506957650184631\n",
            "Epoch: 36, Loss: 0.07330899685621262\n",
            "Epoch: 37, Loss: 0.07169890403747559\n",
            "Epoch: 38, Loss: 0.07018549740314484\n",
            "Epoch: 39, Loss: 0.06874647736549377\n",
            "Epoch: 40, Loss: 0.06738299876451492\n",
            "Epoch: 41, Loss: 0.0660855621099472\n",
            "Epoch: 42, Loss: 0.06483623385429382\n",
            "Epoch: 43, Loss: 0.06363776326179504\n",
            "Epoch: 44, Loss: 0.06248382851481438\n",
            "Epoch: 45, Loss: 0.061379022896289825\n",
            "Epoch: 46, Loss: 0.06032445654273033\n",
            "Epoch: 47, Loss: 0.05932338908314705\n",
            "Epoch: 48, Loss: 0.0583658330142498\n",
            "Epoch: 49, Loss: 0.05745634809136391\n",
            "Epoch: 50, Loss: 0.056574780493974686\n",
            "Epoch: 51, Loss: 0.055740322917699814\n",
            "Epoch: 52, Loss: 0.05494362860918045\n",
            "Epoch: 53, Loss: 0.054186977446079254\n",
            "Epoch: 54, Loss: 0.05346883460879326\n",
            "Epoch: 55, Loss: 0.05279505252838135\n",
            "Epoch: 56, Loss: 0.05215812101960182\n",
            "Epoch: 57, Loss: 0.05154963582754135\n",
            "Epoch: 58, Loss: 0.05095483735203743\n",
            "Epoch: 59, Loss: 0.05037452280521393\n",
            "Epoch: 60, Loss: 0.04982122406363487\n",
            "Epoch: 61, Loss: 0.04930742457509041\n",
            "Epoch: 62, Loss: 0.04883143678307533\n",
            "Epoch: 63, Loss: 0.04836630821228027\n",
            "Epoch: 64, Loss: 0.04791116341948509\n",
            "Epoch: 65, Loss: 0.04747095704078674\n",
            "Epoch: 66, Loss: 0.04707183316349983\n",
            "Epoch: 67, Loss: 0.04668262228369713\n",
            "Epoch: 68, Loss: 0.04630415886640549\n",
            "Epoch: 69, Loss: 0.045936811715364456\n",
            "Epoch: 70, Loss: 0.04558081179857254\n",
            "Epoch: 71, Loss: 0.04523247852921486\n",
            "Epoch: 72, Loss: 0.04489457234740257\n",
            "Epoch: 73, Loss: 0.04456506296992302\n",
            "Epoch: 74, Loss: 0.04423956573009491\n",
            "Epoch: 75, Loss: 0.0439160093665123\n",
            "Epoch: 76, Loss: 0.04359529912471771\n",
            "Epoch: 77, Loss: 0.04327764734625816\n",
            "Epoch: 78, Loss: 0.04296320304274559\n",
            "Epoch: 79, Loss: 0.04265584424138069\n",
            "Epoch: 80, Loss: 0.042355120182037354\n",
            "Epoch: 81, Loss: 0.04205834120512009\n",
            "Epoch: 82, Loss: 0.041765034198760986\n",
            "Epoch: 83, Loss: 0.04147450625896454\n",
            "Epoch: 84, Loss: 0.041186653077602386\n",
            "Epoch: 85, Loss: 0.040901441127061844\n",
            "Epoch: 86, Loss: 0.040621113032102585\n",
            "Epoch: 87, Loss: 0.0403415821492672\n",
            "Epoch: 88, Loss: 0.04006356745958328\n",
            "Epoch: 89, Loss: 0.03978753834962845\n",
            "Epoch: 90, Loss: 0.03951236605644226\n",
            "Epoch: 91, Loss: 0.03923885524272919\n",
            "Epoch: 92, Loss: 0.03896670043468475\n",
            "Epoch: 93, Loss: 0.03869544342160225\n",
            "Epoch: 94, Loss: 0.03842487558722496\n",
            "Epoch: 95, Loss: 0.03816109150648117\n",
            "Epoch: 96, Loss: 0.0378989651799202\n",
            "Epoch: 97, Loss: 0.03763734921813011\n",
            "Epoch: 98, Loss: 0.03738763928413391\n",
            "Epoch: 99, Loss: 0.03713855892419815\n",
            "Epoch: 100, Loss: 0.03688506782054901\n",
            "Epoch: 101, Loss: 0.036629702895879745\n",
            "Epoch: 102, Loss: 0.0363725945353508\n",
            "Epoch: 103, Loss: 0.03611323982477188\n",
            "Epoch: 104, Loss: 0.03585200756788254\n",
            "Epoch: 105, Loss: 0.03559813275933266\n",
            "Epoch: 106, Loss: 0.03534899652004242\n",
            "Epoch: 107, Loss: 0.0350988544523716\n",
            "Epoch: 108, Loss: 0.03484861180186272\n",
            "Epoch: 109, Loss: 0.03459842875599861\n",
            "Epoch: 110, Loss: 0.03434837982058525\n",
            "Epoch: 111, Loss: 0.034099429845809937\n",
            "Epoch: 112, Loss: 0.03385184705257416\n",
            "Epoch: 113, Loss: 0.03361043706536293\n",
            "Epoch: 114, Loss: 0.033396799117326736\n",
            "Epoch: 115, Loss: 0.033174704760313034\n",
            "Epoch: 116, Loss: 0.032947324216365814\n",
            "Epoch: 117, Loss: 0.03272152692079544\n",
            "Epoch: 118, Loss: 0.032492149621248245\n",
            "Epoch: 119, Loss: 0.03226915001869202\n",
            "Epoch: 120, Loss: 0.03204440698027611\n",
            "Epoch: 121, Loss: 0.03184002637863159\n",
            "Epoch: 122, Loss: 0.031642526388168335\n",
            "Epoch: 123, Loss: 0.03145338594913483\n",
            "Epoch: 124, Loss: 0.03125813603401184\n",
            "Epoch: 125, Loss: 0.031057992950081825\n",
            "Epoch: 126, Loss: 0.03085537627339363\n",
            "Epoch: 127, Loss: 0.030649056658148766\n",
            "Epoch: 128, Loss: 0.030461512506008148\n",
            "Epoch: 129, Loss: 0.030273791402578354\n",
            "Epoch: 130, Loss: 0.030078070238232613\n",
            "Epoch: 131, Loss: 0.02987905777990818\n",
            "Epoch: 132, Loss: 0.02968742325901985\n",
            "Epoch: 133, Loss: 0.029487917199730873\n",
            "Epoch: 134, Loss: 0.029297882691025734\n",
            "Epoch: 135, Loss: 0.029120076447725296\n",
            "Epoch: 136, Loss: 0.028930319473147392\n",
            "Epoch: 137, Loss: 0.028737759217619896\n",
            "Epoch: 138, Loss: 0.02855297364294529\n",
            "Epoch: 139, Loss: 0.028382809832692146\n",
            "Epoch: 140, Loss: 0.028203731402754784\n",
            "Epoch: 141, Loss: 0.028015704825520515\n",
            "Epoch: 142, Loss: 0.02783050946891308\n",
            "Epoch: 143, Loss: 0.02766226790845394\n",
            "Epoch: 144, Loss: 0.027492430061101913\n",
            "Epoch: 145, Loss: 0.02731803059577942\n",
            "Epoch: 146, Loss: 0.027133289724588394\n",
            "Epoch: 147, Loss: 0.02694699354469776\n",
            "Epoch: 148, Loss: 0.026775116100907326\n",
            "Epoch: 149, Loss: 0.026606285944581032\n",
            "Epoch: 150, Loss: 0.02642947807908058\n",
            "Epoch: 151, Loss: 0.026259487494826317\n",
            "Epoch: 152, Loss: 0.026087230071425438\n",
            "Epoch: 153, Loss: 0.025915566831827164\n",
            "Epoch: 154, Loss: 0.025748247280716896\n",
            "Epoch: 155, Loss: 0.025580119341611862\n",
            "Epoch: 156, Loss: 0.025416146963834763\n",
            "Epoch: 157, Loss: 0.025254851207137108\n",
            "Epoch: 158, Loss: 0.025093497708439827\n",
            "Epoch: 159, Loss: 0.024942437186837196\n",
            "Epoch: 160, Loss: 0.024786224588751793\n",
            "Epoch: 161, Loss: 0.024626580998301506\n",
            "Epoch: 162, Loss: 0.024473363533616066\n",
            "Epoch: 163, Loss: 0.0243166945874691\n",
            "Epoch: 164, Loss: 0.02415931224822998\n",
            "Epoch: 165, Loss: 0.02401713840663433\n",
            "Epoch: 166, Loss: 0.02387179620563984\n",
            "Epoch: 167, Loss: 0.02371865138411522\n",
            "Epoch: 168, Loss: 0.023564588278532028\n",
            "Epoch: 169, Loss: 0.02341979742050171\n",
            "Epoch: 170, Loss: 0.023272225633263588\n",
            "Epoch: 171, Loss: 0.0231231227517128\n",
            "Epoch: 172, Loss: 0.022986631840467453\n",
            "Epoch: 173, Loss: 0.022847147658467293\n",
            "Epoch: 174, Loss: 0.022704916074872017\n",
            "Epoch: 175, Loss: 0.02255556732416153\n",
            "Epoch: 176, Loss: 0.02240276336669922\n",
            "Epoch: 177, Loss: 0.022270694375038147\n",
            "Epoch: 178, Loss: 0.022128527984023094\n",
            "Epoch: 179, Loss: 0.021993737667798996\n",
            "Epoch: 180, Loss: 0.021860096603631973\n",
            "Epoch: 181, Loss: 0.0217191893607378\n",
            "Epoch: 182, Loss: 0.021592319011688232\n",
            "Epoch: 183, Loss: 0.021461961790919304\n",
            "Epoch: 184, Loss: 0.021327661350369453\n",
            "Epoch: 185, Loss: 0.021193815395236015\n",
            "Epoch: 186, Loss: 0.021069737151265144\n",
            "Epoch: 187, Loss: 0.020933831110596657\n",
            "Epoch: 188, Loss: 0.02082090824842453\n",
            "Epoch: 189, Loss: 0.02069312334060669\n",
            "Epoch: 190, Loss: 0.020549705252051353\n",
            "Epoch: 191, Loss: 0.02042345702648163\n",
            "Epoch: 192, Loss: 0.020295163616538048\n",
            "Epoch: 193, Loss: 0.020164692774415016\n",
            "Epoch: 194, Loss: 0.020051617175340652\n",
            "Epoch: 195, Loss: 0.01992684416472912\n",
            "Epoch: 196, Loss: 0.019797520712018013\n",
            "Epoch: 197, Loss: 0.019658710807561874\n",
            "Epoch: 198, Loss: 0.019539382308721542\n",
            "Epoch: 199, Loss: 0.019410649314522743\n",
            "Epoch: 200, Loss: 0.01929275505244732\n",
            "Epoch: 201, Loss: 0.019175542518496513\n",
            "Epoch: 202, Loss: 0.019049804657697678\n",
            "Epoch: 203, Loss: 0.018917206674814224\n",
            "Epoch: 204, Loss: 0.018803942948579788\n",
            "Epoch: 205, Loss: 0.01869840919971466\n",
            "Epoch: 206, Loss: 0.018578367307782173\n",
            "Epoch: 207, Loss: 0.01845168136060238\n",
            "Epoch: 208, Loss: 0.018335137516260147\n",
            "Epoch: 209, Loss: 0.018233656883239746\n",
            "Epoch: 210, Loss: 0.018112042918801308\n",
            "Epoch: 211, Loss: 0.01798260398209095\n",
            "Epoch: 212, Loss: 0.0178640428930521\n",
            "Epoch: 213, Loss: 0.017749382182955742\n",
            "Epoch: 214, Loss: 0.01764495298266411\n",
            "Epoch: 215, Loss: 0.017528578639030457\n",
            "Epoch: 216, Loss: 0.01740964688360691\n",
            "Epoch: 217, Loss: 0.017298990860581398\n",
            "Epoch: 218, Loss: 0.017187166959047318\n",
            "Epoch: 219, Loss: 0.01707327924668789\n",
            "Epoch: 220, Loss: 0.016958940774202347\n",
            "Epoch: 221, Loss: 0.01684631034731865\n",
            "Epoch: 222, Loss: 0.016739295795559883\n",
            "Epoch: 223, Loss: 0.016632841899991035\n",
            "Epoch: 224, Loss: 0.01652069389820099\n",
            "Epoch: 225, Loss: 0.016407102346420288\n",
            "Epoch: 226, Loss: 0.016304194927215576\n",
            "Epoch: 227, Loss: 0.016189420595765114\n",
            "Epoch: 228, Loss: 0.01608487404882908\n",
            "Epoch: 229, Loss: 0.01598588563501835\n",
            "Epoch: 230, Loss: 0.01587652415037155\n",
            "Epoch: 231, Loss: 0.015773767605423927\n",
            "Epoch: 232, Loss: 0.015672652050852776\n",
            "Epoch: 233, Loss: 0.015564336441457272\n",
            "Epoch: 234, Loss: 0.015462934039533138\n",
            "Epoch: 235, Loss: 0.015363100916147232\n",
            "Epoch: 236, Loss: 0.015260311774909496\n",
            "Epoch: 237, Loss: 0.015159141272306442\n",
            "Epoch: 238, Loss: 0.015062609687447548\n",
            "Epoch: 239, Loss: 0.014967243187129498\n",
            "Epoch: 240, Loss: 0.014863159507513046\n",
            "Epoch: 241, Loss: 0.014762506820261478\n",
            "Epoch: 242, Loss: 0.014663889072835445\n",
            "Epoch: 243, Loss: 0.014574476517736912\n",
            "Epoch: 244, Loss: 0.014478538185358047\n",
            "Epoch: 245, Loss: 0.0143754743039608\n",
            "Epoch: 246, Loss: 0.014286526478827\n",
            "Epoch: 247, Loss: 0.01419209036976099\n",
            "Epoch: 248, Loss: 0.014094806276261806\n",
            "Epoch: 249, Loss: 0.014012236148118973\n",
            "Epoch: 250, Loss: 0.013917680829763412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_test_tensor)\n",
        "  y_pred = (y_pred > 0.5).float()\n",
        "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
        "  print(f'Accuracy: {accuracy.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4iR46SZw5qg",
        "outputId": "1f982e47-40b7-4fe6-b61a-c8c4c2c25152"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5523238182067871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUesmeUZCxiJ",
        "outputId": "200233be-cf28-4b35-e714-6f040f4f062a"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model, input_size=(X_train_tensor.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxX_LMP_FbPj",
        "outputId": "a1a61d16-448e-4b96-dccb-a1c8f4e02821"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "mysimplenn                               [455, 1]                  --\n",
              "├─Sequential: 1-1                        [455, 1]                  --\n",
              "│    └─Linear: 2-1                       [455, 8]                  248\n",
              "│    └─ReLU: 2-2                         [455, 8]                  --\n",
              "│    └─Linear: 2-3                       [455, 1]                  9\n",
              "│    └─Sigmoid: 2-4                      [455, 1]                  --\n",
              "==========================================================================================\n",
              "Total params: 257\n",
              "Trainable params: 257\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.12\n",
              "==========================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 0.03\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.09\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    }
  ]
}